# 第1章 绪论

## 1.1 引言

**机器学习**：致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。研究的主要内容是在计算机上从数据中产生学习算法

## 1.2 基本术语

**记录**：关于一个事件或对象的描述，也称为一个**示例(instance)**或**样本(sample)**

**数据集(data set)**：一组记录的集合

**属性(attribute)**：反映事件或对象在某方面的表现或性质的事项，也称为**特征(feature)**

**属性值(attribute value)**：属性上的取值

**属性空间(attribute space)**：属性张成的空间，也称为**样本空间**或**输入空间**

**学习**或**训练**：从数据中学得模型的过程，通过执行某个学习算法来完成

训练过程中使用的数据称为**训练数据(training data)**，其中每个样本称为一个**训练样本(training sample)**，训练样本组成的集合称为**训练集(training set)**

**标记(label)**：关于示例结果的信息

**样例(example)**：拥有了标记信息的示例

**标记空间(label space)**：所有标记的集合，也称为输出空间

表示方法：
$$
D=\{x_1,x_2,\dots,x_m\}：包含m个示例的数据集\\
x_i=(x_{i1};x_{i2};\dots;x_{id})：包含d个属性描述的示例\\
其中x_{ij}是x_i在第j个属性上的取值\\
(x_i,y_i)表示第i个样例
$$
**分类(classification)**：欲预测的是离散值的学习任务，

**回归(regression)**：欲预测的是分散值的学习任务

**测试样本(testing sample)**：在学得模型后，测试时被预测的样本

**聚类(clustering)**：训练样本中不拥有标记信息，目标是通过对无标记训练样本的学习来解释数据的内在性质及规律。聚类试图将数据集中的样本划分成若干个子集，每个子集称为一个簇(cluster)

学习任务的分类：

- **监督学习(supervised learning)**：训练数据中有标记信息，如分类和回归
- **无监督学习(unsupervised learning)**：训练数据中无标记信息，如聚类

**泛化(generalization)**：学得模型适用于新样本的能力

## 1.3 假设空间

**假设空间(hypothesis space)**：所有假设组成的空间，也就是样本所有可能性的集合

**版本空间(version space)**：在假设空间中存在的一个与训练集一致的假设集合

从假设空间中得到版本空间的方法：在假设空间中进行搜索，搜索过程中不断删除与正例不一致的假设，和与反例一致的假设

# 第2章 模型评估与选择

## 2.1 经验误差与过拟合

**错误率(error rate)**：分类错误的样本数占样本总数的比例

**精度(accuracy)**：分类正确的样本数占样本总数的比例，精度=1-错误率

**误差(error)**：学习器的实际预测输出与样本的真实输出之间的差异

学习器在训练集上的误差称为**训练误差(training error)**或**经验误差(empirical error)**，在新样本上的误差称为**泛化误差(generalization error)**

**过拟合(overfitting)**：学习器把训练样本学得“太好了”，把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，从而导致泛化性能下降。导致过拟合最常见的情况是学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了。过拟合无法彻底避免，只能缓解

**欠拟合(underfitting)**：对训练样本的一般性质尚未学好，原因通常是学习能力低下。解决办法：在决策树学习中扩展分支，在神经网络学习中增加训练轮数等

<img src="西瓜书学习笔记.assets/image-20220615082851156.png" alt="image-20220615082851156" style="zoom:50%;" />

**模型选择**：对于某一任务选择学习算法，并选择参数配置

## 2.2 评估方法

**测试集(testing set)**：测试学习器对新样本的判别能力，用测试误差(testing error)作为泛化误差的近似。测试集应尽可能与训练集互斥

### 2.2.1 留出法（hold-out)

直接将数据集D划分为两个互斥的集合：训练集S和测试集T，在S上训练出模型后，用T来评估其测试误差

*注意：*

- *训练/测试集的划分要尽量保持数据分布的一致性，如分层采样(stratified sampling)*
- *一般要采用若干次随即划分、重复进行实验评估后取平均值作为评估结果*
- *常见做法是将大约2/3~4/5的样本用于训练，其余用于测试*

### 2.2.2 交叉验证法(cross validation)

将数据集D划分为k个大小相似的互斥子集，每个子集D~i~都尽可能保持数据分布的一致性，即从D中分层采样得到

然后每次用k-1个子集的并集作为训练集，剩下的那个子集作为测试集，这样就可以获得k组训练/测试集，可进行k此训练和测试，最终返回k个测试结果的均值

交叉验证法也成为k折交叉验证(k-fold cross validation)，k最常取10

*注意：*

- *交叉验证法也需要减少因样本划分不同而引入的差别，所以要使用不同的划分重复p次，即p次k折交叉验证*

**留一法(Leave-One-Out, LOO)**：数据集D中有m个样本，若令k为m，就是交叉验证法的特例：留一法。留一法不受随机样本划分方式的影响，结果较为准确，但是数据集较大时不适用

### 2.2.3 自助法(bootstrapping)

对包含m个样本的数据集D进行采样，产生数据集D'，方法为：

每次随机从D中挑选一个样本，将其拷贝放入D'，然后再放回D中，这样重复执行m次，就得到了包含m个样本的数据集D'，即有m个训练样本，可能会有重复。通过计算概率，D中约有36.8%的样本没有在D'中，将D’用作训练集，D\D'（没有进入训练集的样本）用作测试集，这样的测试结果也称为包外估计(out-of-bag estimate)

*注意：*

- *自助法在数据集较小、难以有效划分训练/测试集时很有用，但是自助法产生的数据集改变了初始数据集的分布，会引入估计偏差，所以在初始数据量足够时常用留出法和交叉验证法*

### 2.2.4 调参与最终模型

**参数调节**：简称**调参(parameter tuning)**，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需对算法参数进行设定，参数配置不同，学得模型的性能往往有显著区别

常用的调参方法：对每个参数选定一个范围和变化步长，选出几个候选值后，再从中产生选定值，但是往往并不是最佳值

*注意：*

- *在模型评估与选择过程中由于需要留出一部分数据进行评估测试，所以只用了一部分数据训练模型。因此，在模型选择完成后，学习算法和参数配置已选定，此时应该用全部的数据集（用了所有的样本）重新训练模型，这才是我们最终提交给用户的模型*
- *通常把学得模型在实际使用中遇到的数据称为测试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为验
  证集(validation set).例如，在研究对比不同算法的泛化性能时，我们用测试集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参*

## 2.3 性能度量(performance measure)

**均方误差(mean squared error)**：**回归任务**最常用的性能度量
$$
E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_i)-y_i)^2\\
其中D是样例集，D=\{(x_1,y_1),(x_2,y_2),\dots,(x_m,y_m)\}\\
y_i是示例x_i的真实标记\\
f是学习器，f(x)是学习器预测结果
$$
更一般地，对于数据分布D和概率密度函数p，均方误差可描述为
$$
E(f;D)=\int_{x{\sim}D} (f(x)-y)^2 p(x)dx
$$

下面是**分类任务**中常用的性能度量

### 2.3.1 错误率与精度

错误率

：$E(f;D)=\frac{1}{m}\sum_{i=1}^{m}1_A(f(x_i)\neq y_i)$

精度：$acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}1_A(f(x_i)=y_i)=1-E(f;D)$

更一般地，

错误率可描述为：$E(f;D)=\int_{x{\sim}D}1_A(f(x)\neq y) p(x)dx$

精度可描述为：$acc(f;D)=\int_{x{\sim}D}1_A(f(x)=y) p(x)dx=1-E(f;D)$

### 2.3.2 查准率、查全率与F1

分类结果的**混淆矩阵(confusion matrix)**：

<img src="西瓜书学习笔记.assets/image-20220615163334193.png" alt="image-20220615163334193" style="zoom: 33%;" />

其中$TP+FP+TN+FN=样例总数$

**查准率(precision)**：$P=\frac{TP}{TP+FP}$

**查全率(recall)**：$R=\frac{TP}{TP+FN}$

一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低

**P-R曲线**：在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在最后的则是学习器认为最不可能是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，简称 P-R曲线，显示该曲线的图称为P-R图

<img src="西瓜书学习笔记.assets/image-20220615210223881.png" alt="image-20220615210223881" style="zoom: 33%;" />

考虑查准率和查全率的学习器性能度量：

- **平衡点(Break-Event Point, BEP)**：“查准率=查全率”时的取值
- $F_1$度量：$F_1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}$，是查准率和查全率的调和平均
- $F_\beta$度量：$F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}，\begin{cases} \beta>1, 查全率有更大影响\\ \beta=1, 退化为F_1\\ 0<\beta<1, 查准率有更大影响\end{cases}$

