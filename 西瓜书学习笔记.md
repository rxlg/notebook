# 第1章 绪论

## 1.1 引言

**机器学习**：致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。研究的主要内容是在计算机上从数据中产生学习算法

## 1.2 基本术语

**记录**：关于一个事件或对象的描述，也称为一个**示例(instance)**或**样本(sample)**

**数据集(data set)**：一组记录的集合

**属性(attribute)**：反映事件或对象在某方面的表现或性质的事项，也称为**特征(feature)**

**属性值(attribute value)**：属性上的取值

**属性空间(attribute space)**：属性张成的空间，也称为**样本空间**或**输入空间**

**学习**或**训练**：从数据中学得模型的过程，通过执行某个学习算法来完成

训练过程中使用的数据称为**训练数据(training data)**，其中每个样本称为一个**训练样本(training sample)**，训练样本组成的集合称为**训练集(training set)**

**标记(label)**：关于示例结果的信息

**样例(example)**：拥有了标记信息的示例

**标记空间(label space)**：所有标记的集合，也称为输出空间

表示方法：
$$
D=\{x_1,x_2,...,x_m\}：包含m个示例的数据集\\
x_i=(x_{i1};x_{i2};...;x_{id})：包含d个属性描述的示例\\
其中x_{ij}是x_i在第j个属性上的取值\\
(x_i,y_i)表示第i个样例
$$
**分类(classification)**：欲预测的是离散值的学习任务，

**回归(regression)**：欲预测的是分散值的学习任务

**测试样本(testing sample)**：在学得模型后，测试时被预测的样本

**聚类(clustering)**：训练样本中不拥有标记信息，目标是通过对无标记训练样本的学习来解释数据的内在性质及规律。聚类试图将数据集中的样本划分成若干个子集，每个子集称为一个簇(cluster)

学习任务的分类：

- **监督学习(supervised learning)**：训练数据中有标记信息，如分类和回归
- **无监督学习(unsupervised learning)**：训练数据中无标记信息，如聚类

**泛化(generalization)**：学得模型适用于新样本的能力

## 1.3 假设空间

**假设空间(hypothesis space)**：所有假设组成的空间，也就是样本所有可能性的集合

**版本空间(version space)**：在假设空间中存在的一个与训练集一致的假设集合

从假设空间中得到版本空间的方法：在假设空间中进行搜索，搜索过程中不断删除与正例不一致的假设，和与反例一致的假设

# 第2章 模型评估与选择

## 2.1 经验误差与过拟合

**错误率(error rate)**：分类错误的样本数占样本总数的比例

**精度(accuracy)**：精度=1-错误率

**误差(error)**：学习器的实际预测输出与样本的真实输出之间的差异

学习器在训练集上的误差称为**训练误差(training error)**或**经验误差(empirical error)**，在新样本上的误差称为**泛化误差(generalization error)**

**过拟合(overfitting)**：学习器把训练样本学得“太好了”，把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，从而导致泛化性能下降。导致过拟合最常见的情况是学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了。过拟合无法彻底避免，只能缓解

**欠拟合(underfitting)**：对训练样本的一般性质尚未学好，原因通常是学习能力低下。解决办法：在决策树学习中扩展分支，在神经网络学习中增加训练轮数等

![image-20220614234342686](https://cdn.jsdelivr.net/gh/rxlg/pics/img/202206142343770.png)

**模型选择**：对于某一任务选择学习算法，并选择参数配置

## 2.2 评估方法

**测试集(testing set)**：测试学习器对新样本的判别能力，用测试误差(testing error)作为泛化误差的近似。测试集应尽可能与训练集互斥

### 2.2.1 留出法（hold-out)

直接将数据集D划分为两个互斥的集合：训练集S和测试集T，在S上训练出模型后，用T来评估其测试误差

*注意：训练/测试集的划分要尽量保持数据分布的一致性，如分层采样(stratified sampling)'；另外一般要采用若干次随即划分、重复进行实验评估后取平均值作为评估结果；常见做法是将大约2/3~4/5的样本用于训练，其余用于测试*

### 2.2.2 交叉验证法(cross validation)

将数据集D划分为k个大小相似的互斥子集，每个子集D~i~都尽可能保持数据分布的一致性，即从D中分层采样得到

然后每次用k-1个子集的并集作为训练集，剩下的那个子集作为测试集，这样就可以获得k组训练/测试集，可进行k此训练和测试，最终返回k个测试结果的均值

交叉验证法也成为k折交叉验证(k-fold cross validation)，k最常取10

*注意：交叉验证法也需要减少因样本划分不同而引入的差别，所以要使用不同的划分重复p次，即p次k折交叉验证*

**留一法(Leave-One-Out, LOO)**：数据集D中有m个样本，若令k为m，就是交叉验证法的特例：留一法。留一法不受随机样本划分方式的影响，结果较为准确，但是数据集较大时不适用

### 2.2.3 自助法(bootstrapping)

对包含m个样本的数据集D进行采样，产生数据集D'，方法为：

每次随机从D中挑选一个样本，将其拷贝放入D'，然后再放回D中，这样重复执行m次，就得到了包含m个样本的数据集D'，即有m个训练样本，可能会有重复。通过计算概率，D中约有36.8%的样本没有在D'中，将D’用作训练集，D\D'用作测试集，这样的测试结果也称为包外估计(out-of-bag estimate)

*注意：自助法在数据集较小、难以有效划分训练/测试集时很有用，但是自助法产生的数据集改变了初始数据集的分布，会引入估计偏差，所以在初始数据量足够时常用留出法和交叉验证法*





